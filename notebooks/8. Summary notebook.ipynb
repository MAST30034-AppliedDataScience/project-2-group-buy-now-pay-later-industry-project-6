{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7a8a500-86fe-4a25-932f-51ef5a719b62",
   "metadata": {},
   "source": [
    "# PROJECT SUMMARY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d851d28-26e9-4611-9ac6-f2ef66216b35",
   "metadata": {},
   "source": [
    "Due to limited resources, our BNPL business aims to work with 100 merchants only. This project seeks to construct a highly interpretable and robust rating system, providing insights to help the organisation locate the appropriate merchants."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910d1843-f622-44f2-9f20-73c024565ac1",
   "metadata": {},
   "source": [
    "![Alt Text](../plots/bnpl.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45197a04-efd8-40db-b1b1-68bcd65c3464",
   "metadata": {},
   "source": [
    "### Questions for ranking\n",
    "\n",
    "How much does each merchant make?\n",
    "\n",
    "How large is their customer base?\n",
    "\n",
    "Are their customers loyal?\n",
    "\n",
    "Are our customers and merchants trustworthy?\n",
    "\n",
    "How much are we going to get ?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff705f5a-cf46-4c1d-98f8-1d827750d1e2",
   "metadata": {},
   "source": [
    "## Methodology\n",
    "\n",
    "1. Pre-process provided data and external ABS data\n",
    "\n",
    "2. Model missing customer and merchant fraud data\n",
    "\n",
    "3. Visualize and explore patterns\n",
    "\n",
    "4. Model each merchants’ future performance\n",
    "\n",
    "5. Cluster merchants into relevant segments\n",
    "\n",
    "6. Rank merchants for usage by a BNPL firm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d7d83ba-055c-4a39-9899-3d04c8fb107f",
   "metadata": {},
   "source": [
    "## Provided Data\n",
    "\n",
    "14 million individual transactions\n",
    "\n",
    "Consumer’s details (Address,...)\n",
    "\n",
    "Merchant’s details(ABN, describing tags…)\n",
    "\n",
    "Fraud data for both consumers and merchants"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e1edb3f-5cfd-421b-9600-92b58b40258c",
   "metadata": {},
   "source": [
    "## External data\n",
    "We also get the following external datasets:\n",
    "\n",
    "2021 Australia census data\n",
    "\n",
    "Postcode to Statistical Area 2 (SA2) code mapping table\n",
    "\n",
    "SA2 boundaries shapefile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "face8d14-e5ab-4d15-8f6c-1df5316b2169",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "\n",
    "### Explore transaction\n",
    "\n",
    "![Alt Text](../plots/transaction_dollar.png)\n",
    "\n",
    "We observe close to 0 transaction, which is very unlikely due to the lack of product in the range and rational consumer shouldn't lend money for such a small purchase. More than 10,000 dollar transaction also appear, which is unlikely and won't be taken into consideration as the BNPL industry ban transactions of more than few thousands due to the risk involve. Both of these are abnormal and can be sign of fraudulent.\n",
    "\n",
    "#### We thus remove outlier. Outliers are defined as data points that fall outside range:\n",
    "𝑄\n",
    "1\n",
    "−\n",
    "1.5\n",
    "×\n",
    "IQR\n",
    "and above:\n",
    "𝑄\n",
    "3\n",
    "+\n",
    "1.5\n",
    "×\n",
    "IQR\n",
    "\n",
    "After removal, here is the observed distribution\n",
    "\n",
    "![Alt Text](../plots/clean_transaction.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ca0ad7-db1c-4408-a45f-06806ea6c13c",
   "metadata": {},
   "source": [
    "## Explore and impute missing consumer fraud\n",
    "\n",
    "![Alt Text](../plots/consumer_fraud.png)\n",
    "\n",
    "Despite not using transaction > 2000 to predict future merchant performance and ranking and we advise our BNPL firm to strictly apply this according to industry practice. We still use full range transaction in modeling fraud. we observe a strong linear relationship between customer spending and fraud probability. The connection between fraud and number of order is less obvious. \n",
    "\n",
    "\n",
    "#### We chose to impute consumer fraud data using a linear regression model with AIC stepwise selection. \n",
    "This is the final model that we come up with and its performance:\n",
    "\n",
    "#### Predictors and their Coefficients:\n",
    "\n",
    "total_spent: 2.0996552300408644e-05\n",
    "\n",
    "total_spent_per_order: 6.228304562183401e-06\n",
    "\n",
    "total_spent_squared: -1.8457767617199225e-10\n",
    "\n",
    "num_orders_squared: 0.0006513709972329626\n",
    "\n",
    "Intercept: 0.03455972479087561\n",
    "\n",
    "Final RMSE: 0.03886892546091528\n",
    "R-squared: 0.8526665350226852"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994c871e-3295-4e87-be8c-0914560b751b",
   "metadata": {},
   "source": [
    "## Explore and impute merchant fraud\n",
    "\n",
    "Percentage of merchants with fraud data is 1.55% and this is only available for serveral days, meaning > 99.9% of the data is missing.\n",
    "\n",
    "![Alt Text](../plots/merchant_fraud1.png)\n",
    "![Alt Text](../plots/merchant_fraud2.png)\n",
    "\n",
    "Correlation between fraud_probability and total_money: -0.3411541778846223\n",
    "\n",
    "Correlation between fraud_probability and num_transactions: -0.24645163406918985\n",
    "\n",
    "Correlation between fraud_probability and avg_transaction_value: 0.2673609612684381\n",
    "\n",
    "### We decided to use a very simple decision tree to impute fraud. Howevever, in this case (>99.9% missing) we can discard this entire data to ensure validity as too many records are lacking. We can also use mean imputation as our final objective is ranking and mean imputation ensure fair treatment among those unobserved merchants. \n",
    "\n",
    "Using maxdepth selected of 2, and train test split 9:1. Here is the performance\n",
    "\n",
    "RMSE: 6.046683793780371\n",
    "R-squared: 0.8115129482946885\n",
    "\n",
    "Though we must noted that for our case where so many records are missing. The validity of this in imputation is questionable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "903d9122-1235-4b87-b320-b35194e228fe",
   "metadata": {},
   "source": [
    "## External ABS data handling\n",
    "\n",
    "We will link our custumer with their related information in ABS. However as we only know our postcode and their address in synthesize using the USA address, this pose challenge in linking. As postcodes may be matched to multiple SA2 regions, therefore we will choose the region with the highest ratio (percentage of population for that postcode) as representative.\n",
    "\n",
    "![Alt Text](../plots/outlier_abs.png)\n",
    "\n",
    "We should remove instances which include outlier values for some features. For example, we can see that minimum values for a lot of the statistics are zero, which doesn't make sense. We should also remove any NaN values.'\n",
    "\n",
    "![Alt Text](../plots/abs.png)\n",
    "\n",
    "We interest in the median income for our final ranking objective. We highly expect that our customer can repay their debt and we hope to attract more spending from high income group through target advertising in the future\n",
    "\n",
    "![Alt Text](../plots/geo1.png)\n",
    "![Alt Text](../plots/geo2.png)\n",
    "![Alt Text](../plots/geo3.png)\n",
    "\n",
    "We can see that our merchants attract orders from all across Australia. Having a large customer base and customers coming from many regions is advantagous as our brand can be exposed to more people, attracting more customers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e29acb9-22a9-458d-9f12-e7cb8a9f6d5c",
   "metadata": {},
   "source": [
    "# Model merchant future performance\n",
    "\n",
    "In our business model, for a transaction like a bicycle cost 100 dollar. We pay our merchant 94 dollar right away (6% take rate). We expect our honest user to pay us back 100 dollar, thus we gain 6 dollar. However when fraud happen with our user, we lost 94. Here, We assume that we can't recover anything here for simplicity. In reality we the recover rate can be a% and we adjust the loss calculation respectively. \n",
    "\n",
    "Here we don't incorporate merchant fraud in our calculation. For customer, since there are many of them so some level of fraud is acceptable as we still have many more honest customer. But for merchant is special, as there are only 100 and we need high level of trust in this business model, if we discover 1 case of fraud, we stop cooperate with them right away, bring them to court and ask for compensation. These terms need to be highlight in our contract."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d60c08b6-e46a-4279-a434-424eb8cb1cfd",
   "metadata": {},
   "source": [
    "![Alt Text](../plots/commision.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ffb27bf-2508-484e-9cf2-9f903258b3bc",
   "metadata": {},
   "source": [
    "### We will use the past data to model our merchant next 6 months's commission. Our model of choice is SARIMAX\n",
    "\n",
    "# SARIMAX Model Overview\n",
    "\n",
    "The **SARIMAX** model (Seasonal AutoRegressive Integrated Moving Average with eXogenous variables) is chosen for forecasting because it is designed for time series data. It incorporates several key components:\n",
    "\n",
    "- **Auto-regression (AR)**: Uses past values of the target variable to predict future values.\n",
    "- **Moving Average (MA)**: Utilizes past forecast errors to make predictions.\n",
    "- **Integrated (I)**: Applies differencing to the series in order to make it stationary.\n",
    "- **Seasonality**: Captures seasonal patterns in the data (e.g., weekly, monthly seasonality).\n",
    "\n",
    "### Hyperparameters of the SARIMAX Model\n",
    "\n",
    "The SARIMAX model requires several hyperparameters to be defined:\n",
    "\n",
    "- **p**: The number of lag observations in the AR model (the number of previous terms used for prediction).\n",
    "- **d**: The number of differences applied to make the time series stationary.\n",
    "- **q**: The number of lagged forecast errors in the MA model.\n",
    "- **P, D, Q, m**: These are the seasonal components:\n",
    "  - **P**: Seasonal autoregressive order.\n",
    "  - **D**: Seasonal differencing order.\n",
    "  - **Q**: Seasonal moving average order.\n",
    "  - **m**: The number of observations per season.\n",
    "\n",
    "These parameters allow the model to capture both short-term and seasonal patterns in the data, making it ideal for time series forecasting.\n",
    "\n",
    "## We first find out the hyperparameter\n",
    "\n",
    "### Get the average profit across all merchant in every date. Then treat it as a representative merchant for finding the best parameters and visualizing. We apply grid search for best hyperparameter using AIC.\n",
    "\n",
    "![Alt Text](../plots/forecast.png)\n",
    "\n",
    "### We then apply this for nearly 4000 merchants, as every single merchants have different model, this take significant time to train\n",
    "\n",
    "### At the end there are 30 merchants out of 3930 where MLE fail to converge. these are merchant likely having 0 revenues for days or have revenues fluctuate highly. Thus MLE fail to converge. But they account for less then 1% so we will remove them. Otherwise we can impute these with last 6 months revenue."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c937cfb2-5f69-4887-99b7-439fb9ae72c6",
   "metadata": {},
   "source": [
    "# Segmenting business\n",
    "\n",
    "We have to clean the merchant tags (removing stop word, lemmatize and one hot encode....). After all we extract 84 words which is display using this word cloud, these hint at the products and services provided by our merchants. \n",
    "\n",
    "![Alt Text](../plots/cloud.png)\n",
    "\n",
    "We finally group into 9 clusters. K-mean clustering is used but the final clusters are decided based on domain knowledge of business products. For example group involve \"computer\", \"system\", \"programming\"... is named \"IT and tech gadgets\"...\n",
    "\n",
    "![Alt Text](../plots/cluster.png)\n",
    "\n",
    "# Groups and their overall performance\n",
    "\n",
    "![Alt Text](../plots/cluster_stat1.png)\n",
    "\n",
    "![Alt Text](../plots/cluster_stat2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b64a3cf-a059-483d-842d-da7f3a7a268a",
   "metadata": {},
   "source": [
    "#### We find that Art and Decors lead in both revenue, orders and returned commission. Business like Housing applicances rank 4th in revenue but rank 7th in total orders, indicating that their transactions are of high value. Business like sourvenir and gift rank 8th in revenue but rank 4th in total order, indicating that their transactions are of low value. These difference will be noted when we later calculate the ranking score.\n",
    "\n",
    "#### We decided to take top 5 most numerous groups(Arts and Decors, IT and Tech Gadgets, Leisure and Hobbies, Housing Applicances and Furnitures, Accessories and Luxuries), these are also in top 5 for revenue and profit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d765bde6-0820-4588-aac3-69e8c15ee890",
   "metadata": {},
   "source": [
    "# RANKING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e85afc2-259c-489c-aff7-b0cb465db48d",
   "metadata": {},
   "source": [
    "![Alt Text](../plots/summary1.png)\n",
    "![Alt Text](../plots/summary2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c42903b-ca44-452b-8bf8-62fddbc807bf",
   "metadata": {},
   "source": [
    "### Candidates features for final ranking:\n",
    "\n",
    "commission\n",
    "\n",
    "merchant_fraud\n",
    "\n",
    "user_number\n",
    "\n",
    "region_reached\n",
    "\n",
    "median_income\n",
    "\n",
    "user_returned_rate\n",
    "\n",
    "merchant_revenue\n",
    "\n",
    "### We expect our merchants to have high revenue, number of user, high number of regions reached and high returned rates for their customer. They need to bring us high commission, and most importantly they need to have low fraud rate\n",
    "\n",
    "![Alt Text](../plots/matrix.png)\n",
    "\n",
    "Inspecing the correlation matrix, we find out that some features highly correlated with each other, like between merchant_revenue and commission(0.92) or between region_reached and num_user(0.81). We decided to remove revenue and region_reached to reduce this intercorrelation, ensuring that they contribute independent value to the ranking score. This ensure that if 1 merchant gain advantage in 1 facet, they don't get scaled up too much and gain an unfair advantage.\n",
    "\n",
    "![Alt Text](../plots/score.png)\n",
    "\n",
    "The ranking score is just a simple linear combination of features. Since there is no inherent labels for our merchant for trainning or evaluating, we can't employ more sophisticated ranking method and it all up to us to decide what suitable. Feature_i get min-max scaling. For fraud_rate since we want lower not higher fraud rate so we will transform to 1-fraud_rate in scoring. The weightings sum to 1. Different businesses will have different features weighting. \n",
    "\n",
    "0.5, 0.2, 0.1, 0.1, 0.1 is the general weighting for commission, fraud, num_user, median_income, returned_rate. Here we put high weighting on commission as this is what our business run on. Fraud rate also get high weighting as we won't tolerate fraud for merchant in our business. This also get adjusted for different businesses. For example, for housing applicances and furnising as this business has high value transaction, we put more weight on fraud and median income(to lower the risk) and less weight on user number. Though based on the nature of our BNPL firm's business and requirement, these will be changed more according the their adjustment. \n",
    "\n",
    "# TOP 10 per businesses\n",
    "\n",
    "![Alt Text](../plots/top10.png)\n",
    "\n",
    "Here we can observe some downward trend of num user and commission from to 1 to 10 in our business. Fraud rate has some upward trend from top 1 to 10\n",
    "\n",
    "# TOP 100 merchants\n",
    "\n",
    "![Alt Text](../plots/top100.png)\n",
    "\n",
    "Here we again observe clear downward trend for commission from top 1 to 100 as we put very high weighting on commission. the pattern for number of user is less obvious where we observe some upward trend for fraud rate.\n",
    "\n",
    "\n",
    "![Alt Text](../plots/100cluster.png)\n",
    "\n",
    "the proportion of different business in top 100 seem to highly reflect their innitial proportion ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1beba365-f43f-401e-b6e7-99e90096eebf",
   "metadata": {},
   "source": [
    "# Assumptions\n",
    "\n",
    "No confounding factors other than the features included in our data\n",
    "\n",
    "Consumer address is likely linked to the most populous SA2 district if a postcode is said to belong to two SA2 districts\n",
    "\n",
    "Individual consumer’s income can be represented by the median of their SA2.\n",
    "\n",
    "Consumer fraud is not insured or fully recovered, so the BNPL business loses all fraudulent transactions\n",
    "\n",
    "# Limitations and difficulties\n",
    "\n",
    "Missing Data: Our biggest obstacle was dealing with missing data, e.g. missing fraud rate data,....\n",
    "\n",
    "Small Dataset: Our transactions data only covers ~1.5 years. A larger range of data would be beneficial in determining consumer patterns over years.\n",
    "\n",
    "Significant time to train SARIMAX for nearly 4000 merchants.\n",
    "\n",
    "External Correspondence: mismatches when dealing with the external dataset, e.g. SA2 regions are not 1-to-1 with postcodes.\n",
    "\n",
    "No ranking label available (similar to how QS rank universities), it’s all up to us to decide the directions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ede4db-213e-47a0-9e04-97b438540032",
   "metadata": {},
   "source": [
    "# Future improment and application\n",
    "\n",
    "Firstly, we can enhance our model for rating customer fraud and create a credit rating system that decide whether a transaction is accepted or not. But we will need multi layer authentication, integration with bank account, credit data from third parties….\n",
    "\n",
    "Secondly, we can bring our ranking model into production. Merchants having interest will submit through an online portal, and we accept them if they pass through certain point. We will build an automatic pipeline for this. \n",
    "\n",
    "Thirdly, we can build bots scraping the internet, social media for potential merchant and feed into our model. If our candidate passes, we will automatically send an invitation email. If things go well, our sales team will further contact them to negotiate terms. Though, we need to aware of privacy in this.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f62a35-6bbc-4035-8637-d67aa4f19b1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
